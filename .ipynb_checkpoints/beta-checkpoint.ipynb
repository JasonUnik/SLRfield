{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 选源"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pathlib import Path\n",
    "from os import path,makedirs\n",
    "#from datetime import date\n",
    "\n",
    "def discos_query(COSPARID = None,NORADID = None,ObjectClass = None,Decayed=None,DecayDate = None,Mass = None,RCSMin = None,RCSMax = None,RCSAvg = None,sort = None,outfile=True):\n",
    "    '''\n",
    "    objectClass -> None, Payload, Payload Debris, Payload Fragmentation Debris, Payload Mission Ralated Object, Rocket Body, Rocket Debris, Rocket Fragmentation Debris, Rocket Mission Related Object, Unknown\n",
    "    '''\n",
    "    \n",
    "    # discos token\n",
    "    home = str(Path.home())\n",
    "    direc = home + '/src/discos-data/'\n",
    "    tokenfile = direc + 'discos-token'\n",
    "\n",
    "    if not path.exists(direc): makedirs(direc)\n",
    "    if not path.exists(tokenfile):\n",
    "        token = input('Please input the DISCOS token(which can be achieved from https://discosweb.esoc.esa.int/tokens): ')\n",
    "        outfile = open(tokenfile,'w')\n",
    "        outfile.write(token)\n",
    "        outfile.close()\n",
    "    else:\n",
    "        infile = open(tokenfile,'r')\n",
    "        token = infile.readline()\n",
    "        infile.close()\n",
    "    \n",
    "    URL = 'https://discosweb.esoc.esa.int'\n",
    "    params = {}\n",
    "    \n",
    "    if ObjectClass is not None:\n",
    "        if type(ObjectClass) is str:\n",
    "            params['filter'] = \"eq(objectClass,'{:s}')\".format(ObjectClass)\n",
    "        elif type(ObjectClass) is list:\n",
    "            params_filter = []\n",
    "            for element in ObjectClass:\n",
    "                params_filter.append(\"eq(objectClass,'{:s}')\".format(element))\n",
    "            params['filter'] = '|'.join(params_filter)\n",
    "            params['filter'] = '(' + params['filter'] + ')'\n",
    "        else:\n",
    "            raise Exception('Type of ObjectClass should be either string or list.')\n",
    "            \n",
    "    # Decayed\n",
    "    if Decayed is not None:\n",
    "        if Decayed is False:\n",
    "            if 'filter' in params.keys():\n",
    "                params['filter'] += \"&(eq(reentry.epoch,null))\"\n",
    "            else:\n",
    "                params['filter'] = \"eq(reentry.epoch,null)\"\n",
    "        elif Decayed is True:\n",
    "            if 'filter' in params.keys():\n",
    "                params['filter'] += \"&(ne(reentry.epoch,null))\"\n",
    "            else:\n",
    "                params['filter'] = \"ne(reentry.epoch,null)\"\n",
    "        else:\n",
    "            raise Exception(\"'Decayed' must be one of 'False', 'True', or 'None'.\")   \n",
    "            \n",
    "    # decaydate\n",
    "    if DecayDate is not None:\n",
    "        #date_now = date.today().isoformat()\n",
    "            \n",
    "        if 'filter' in params.keys():\n",
    "            params['filter'] += \"&(gt(reentry.epoch,epoch:'{:s}')&lt(reentry.epoch,epoch:'{:s}'))\".format(DecayDate[0],DecayDate[1])\n",
    "        else:\n",
    "            params['filter'] = \"gt(reentry.epoch,epoch:'{:s}')&lt(reentry.epoch,epoch:'{:s}')\".format(DecayDate[0],DecayDate[1])\n",
    " \n",
    "              \n",
    "    if COSPARID is not None:\n",
    "        if 'filter' in params.keys():\n",
    "            if type(COSPARID) is str:\n",
    "                params['filter'] += \"&(eq(cosparId,'{:s}'))\".format(COSPARID)\n",
    "            elif type(COSPARID) is list:    \n",
    "                params['filter'] += '&(in(cosparId,{:s}))'.format(str(tuple(COSPARID))).replace(' ', '')\n",
    "            else:\n",
    "                raise Exception('Type of COSPARID should be in str or list of str.')\n",
    "        else:\n",
    "            if type(COSPARID) is str:\n",
    "                params['filter'] = \"eq(cosparId,'{:s}')\".format(COSPARID)\n",
    "            elif type(COSPARID) is list:    \n",
    "                params['filter'] = 'in(cosparId,{:s})'.format(str(tuple(COSPARID))).replace(' ', '')\n",
    "            else:\n",
    "                raise Exception('Type of COSPARID should be in str or list of str.')\n",
    "            \n",
    "            \n",
    "    if NORADID is not None:\n",
    "        if 'filter' in params.keys():\n",
    "            if type(NORADID) is int:\n",
    "                params['filter'] += '&(eq(satno,{:d}))'.format(NORADID)   \n",
    "            elif type(NORADID) is str:\n",
    "                params['filter'] += '&(eq(satno,{:s}))'.format(NORADID)\n",
    "            elif type(NORADID) is list:    \n",
    "                params['filter'] += '&(in(satno,{:s}))'.format(str(tuple(NORADID))).replace(' ', '')\n",
    "            else:\n",
    "                raise Exception('Type of NORADID should be in int, str, list of int, or list of str.')  \n",
    "        else:\n",
    "            if type(NORADID) is int:\n",
    "                params['filter'] = 'eq(satno,{:d})'.format(NORADID)   \n",
    "            elif type(NORADID) is str:\n",
    "                params['filter'] = 'eq(satno,{:s})'.format(NORADID)\n",
    "            elif type(NORADID) is list:    \n",
    "                params['filter'] = 'in(satno,{:s})'.format(str(tuple(NORADID))).replace(' ', '')\n",
    "            else:\n",
    "                raise Exception('Type of NORADID should be in int, str, list of int, or list of str.') \n",
    "            \n",
    "                \n",
    "    if RCSMin is not None:\n",
    "        if 'filter' in params.keys():\n",
    "            params['filter'] += '&(gt(xSectMin,{:.4f})&lt(xSectMin,{:.4f}))'.format(RCSMin[0],RCSMin[1])\n",
    "        else:\n",
    "            params['filter'] = 'gt(xSectMin,{:.4f})&lt(xSectMin,{:.4f})'.format(RCSMin[0],RCSMin[1])\n",
    "            \n",
    "        \n",
    "    if RCSMax is not None:\n",
    "        if 'filter' in params.keys():\n",
    "            params['filter'] += '&(gt(xSectMax,{:.4f})&lt(xSectMax,{:.4f}))'.format(RCSMax[0],RCSMax[1])  \n",
    "        else:\n",
    "            params['filter'] = 'gt(xSectMax,{:.4f})&lt(xSectMax,{:.4f})'.format(RCSMax[0],RCSMax[1])\n",
    "            \n",
    "        \n",
    "    if RCSAvg is not None:\n",
    "        if 'filter' in params.keys():\n",
    "            params['filter'] += '&(gt(xSectAvg,{:.4f})&lt(xSectAvg,{:.4f}))'.format(RCSAvg[0],RCSAvg[1]) \n",
    "        else:\n",
    "            params['filter'] = 'gt(xSectAvg,{:.4f})&lt(xSectAvg,{:.4f})'.format(RCSAvg[0],RCSAvg[1])\n",
    "            \n",
    "    if sort is None:    \n",
    "        params['sort'] = 'satno'  \n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    # initial params for page\n",
    "    params['page[number]'] = 1\n",
    "    extract = []\n",
    "    \n",
    "    while True:\n",
    "        params['page[size]'] = 100 # mumber of entries for each page   \n",
    "        response = requests.get(f'{URL}/api/objects',headers = {'Authorization': f'Bearer {token}'},params = params)\n",
    "        doc = response.json()\n",
    "\n",
    "        if response.ok:\n",
    "            data = doc['data']\n",
    "            for element in data:\n",
    "                extract.append(element['attributes'])\n",
    "            currentPage = doc['meta']['pagination']['currentPage']\n",
    "            totalPages = doc['meta']['pagination']['totalPages']\n",
    "            \n",
    "            print('CurrentPage {:3d} in TotalPages {:3d}'.format(currentPage,totalPages))\n",
    "            \n",
    "            if currentPage < totalPages: \n",
    "                params['page[number]'] += 1\n",
    "            else:\n",
    "                break\n",
    "        else:\n",
    "            return doc['errors']\n",
    "        \n",
    "    old_column = ['height', 'xSectMax', 'name', 'satno', 'vimpelId', 'objectClass','mass', 'xSectMin', 'depth', 'xSectAvg', 'length', 'shape', 'cosparId']\n",
    "    new_column = ['Height[m]', 'RCSMax[m2]', 'Satellite Name', 'NORADID', 'VimpelId', 'ObjectClass', 'Mass[kg]', 'RCSMin[m2]', 'Depth[m]', 'RCSAvg[m2]', 'Length[m]', 'Shape', 'COSPARID']\n",
    "    new_column_reorder = ['COSPARID', 'NORADID', 'VimpelId', 'Satellite Name','ObjectClass','Mass[kg]','Shape','Height[m]','Length[m]','Depth[m]','RCSMin[m2]','RCSMax[m2]','RCSAvg[m2]']\n",
    "    df = pd.DataFrame.from_dict(extract,dtype=object).rename(columns=dict(zip(old_column, new_column)), errors='raise')\n",
    "    df = df.reindex(columns=new_column_reorder) \n",
    "    if outfile: df.to_csv('discos_catalog.csv')\n",
    "        \n",
    "    return df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "from datetime import datetime,timedelta\n",
    "from os import path,makedirs,remove\n",
    "from pathlib import Path\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "def download_satcat():\n",
    "    '''\n",
    "    Download or update the space weather file from www.celestrak.com\n",
    "    Usage: \n",
    "    swfile = download_sw([direc])\n",
    "    Inputs: \n",
    "    direc -> [str, optionanl, default = $HOME+'/src/sw-data/'] Directory for storing sw file\n",
    "    \n",
    "    Outputs: \n",
    "    swfile -> [str] Path of sw file\n",
    "    Examples:\n",
    "    >>> swfile = download_sw()\n",
    "    Downloading the latest space weather data ... Finished\n",
    "    >>> print(swfile)\n",
    "    /Users/lichunxiao/src/sw-data/SW-All.txt\n",
    "    >>> swfile = download_sw('sw-data/')\n",
    "    Downloading the latest space weather data ... Finished\n",
    "    >>> swfile = download_sw('sw-data/')\n",
    "    The existing space weather data is already up to date\n",
    "    >>> print(swfile)\n",
    "    sw-data/SW-All.txt\n",
    "    '''\n",
    "    \n",
    "    home = str(Path.home())\n",
    "    direc = home + '/src/satcat-data/'\n",
    "    \n",
    "    scfile = direc + 'satcat.txt'\n",
    "    url = 'https://celestrak.com/pub/satcat.txt'\n",
    "\n",
    "    if not path.exists(direc): makedirs(direc)\n",
    "\n",
    "    if not path.exists(scfile):\n",
    "        print('Downloading the latest satellite catalog from celestrak',end=' ... ')\n",
    "        urlretrieve(url, scfile)\n",
    "        print('Finished')\n",
    "\n",
    "    else:\n",
    "        modified_time = datetime.fromtimestamp(path.getmtime(scfile))\n",
    "        if datetime.now() > modified_time + timedelta(days=7):\n",
    "            remove(scfile)\n",
    "            print('Updating the satellite catalog from celestrak',end=' ... ')\n",
    "            urlretrieve(url, scfile)    \n",
    "            print('Finished')\n",
    "        else:\n",
    "            print('The satellite catalog in {:s} is already the latest.'.format(direc))    \n",
    "    return scfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "def celestrak_query(COSPARID = None, NORADID = None, Payload = None,Decayed = None,DecayDate = None,OrbitalPeriod = None,Inclination = None,ApoAlt = None,PerAlt = None,MeanAlt = None,Country = None,sort = None,outfile=True):\n",
    "    '''\n",
    "    Download the Raw SATCAT Data from https://celestrak.com/pub/satcat.txt\n",
    "    Set the field width according to SATCAT Format Documentation[https://celestrak.com/satcat/satcat-format.php]\n",
    "    '''\n",
    "    set_colspecs = [(0,11),(13,18),(19,20),(20,21),(21,22),(23,47),(49,54),(56,66),(68,73),\\\n",
    "                    (75,85),(87,94),(96,101),(103,109),(111,117),(119,127),(129,132)]\n",
    "    satcat_file = download_satcat()\n",
    "    data = pd.read_fwf(satcat_file, colspecs = set_colspecs, header = None) \n",
    "\n",
    "    data.columns = ['COSPARID', 'NORADID', 'Multiple Name Flag', 'Payload Flag','Operational Status Code','Satellite Name',\\\n",
    "                    'Country','Launch Date','Launch Site','Decay Date','Orbital period[min]','Inclination[deg]',\\\n",
    "                    'Apogee Altitude[km]','Perigee Altitude[km]','Radar Cross Section[m2]','Orbital Status Code']\n",
    "\n",
    "    Mean_Alltitude = (data['Apogee Altitude[km]'] + data['Perigee Altitude[km]'])/2 # mean alltitude[kilometers]\n",
    "    full_of_true = np.ones_like(Mean_Alltitude,dtype=bool)\n",
    "    \n",
    "    # COSPARID \n",
    "    if COSPARID is not None:\n",
    "        if type(COSPARID) in [str,list]:\n",
    "            COSPARID_flag = np.in1d(data['COSPARID'],COSPARID,assume_unique=True)\n",
    "        else:\n",
    "            raise Exception('Type of COSPARID should be in str or list of str.')             \n",
    "    else:\n",
    "        COSPARID_flag = full_of_true\n",
    "    \n",
    "    # NORADID \n",
    "    if NORADID is not None:\n",
    "        if type(NORADID) is int:\n",
    "            NORADID_flag = np.in1d(data['NORADID'],NORADID,assume_unique=True)\n",
    "        elif type(NORADID) is str:   \n",
    "            NORADID_flag = np.in1d(data['NORADID'],int(NORADID),assume_unique=True)\n",
    "        elif type(NORADID) is list:\n",
    "            NORADID_flag = np.in1d(data['NORADID'],np.array(NORADID).astype(int),assume_unique=True)\n",
    "        else:\n",
    "            raise Exception('Type of NORADID should be in int, str, list of int, or list of str.')             \n",
    "    else:\n",
    "        NORADID_flag = full_of_true\n",
    "    \n",
    "    # payload\n",
    "    Payload_flag = data['Payload Flag'] == '*'\n",
    "    if Payload is True:\n",
    "        pass\n",
    "    elif Payload is False:\n",
    "        Payload_flag = ~Payload_flag\n",
    "    else:\n",
    "        Payload_flag = full_of_true\n",
    "        \n",
    "    # decayed \n",
    "    Decayed_flag = data['Operational Status Code'] == 'D'\n",
    "    if Decayed is True:\n",
    "        pass\n",
    "    elif Decayed is False:\n",
    "        Decayed_flag = ~Decayed_flag\n",
    "    else:\n",
    "        Decayed_flag = full_of_true\n",
    "       \n",
    "    # apoAlt\n",
    "    if ApoAlt is not None:\n",
    "        ApoAlt_flag = (data['Apogee Altitude[km]'] > ApoAlt[0]) & (data['Apogee Altitude[km]'] < ApoAlt[1])\n",
    "    else:\n",
    "        ApoAlt_flag = full_of_true\n",
    "        \n",
    "    # perAlt\n",
    "    if PerAlt is not None:\n",
    "        PerAlt_flag = (data['Perigee Altitude[km]'] > PerAlt[0]) & (data['Perigee Altitude[km]'] < PerAlt[1])\n",
    "    else:\n",
    "        PerAlt_flag = full_of_true\n",
    "        \n",
    "    # MeanAlt\n",
    "    if MeanAlt is not None:\n",
    "        MeanAlt_flag = (Mean_Alltitude > MeanAlt[0]) & (Mean_Alltitude < MeanAlt[1])\n",
    "    else:\n",
    "        MeanAlt_flag = full_of_true    \n",
    "       \n",
    "    selected_flag = COSPARID_flag & NORADID_flag & Payload_flag & Decayed_flag & ApoAlt_flag & PerAlt_flag & MeanAlt_flag\n",
    "    df = data[selected_flag].drop(['Multiple Name Flag','Operational Status Code','Orbital Status Code'],axis=1)\n",
    "    column_reorder = ['COSPARID', 'NORADID', 'Satellite Name','Payload Flag','Decay Date',\\\n",
    "                      'Orbital period[min]', 'Inclination[deg]','Apogee Altitude[km]', 'Perigee Altitude[km]',\\\n",
    "                      'Launch Date','Launch Site','Radar Cross Section[m2]','Country']\n",
    "    df = df.reindex(columns=column_reorder)\n",
    "    if outfile: df.to_csv('celestrak_catalog.csv')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_query(COSPARID=None,NORADID=None,Payload=None,ObjectClass=None,Mass=None,Decayed=None,DecayDate=None,OrbitalPeriod=None,Inclination=None,ApoAlt=None,PerAlt=None,MeanAlt=None,RCSMin=None,RCSMax=None,RCSAvg=None,Country=None,outfile=True):\n",
    "    df_celestrak = celestrak_query(COSPARID,NORADID,Payload,Decayed,DecayDate,OrbitalPeriod,Inclination,ApoAlt,PerAlt,MeanAlt,Country,outfile=False).drop('Satellite Name',axis=1)\n",
    "    print('Go through the DISCOS database:')\n",
    "    df_discos = discos_query(COSPARID,NORADID,ObjectClass,Decayed,DecayDate,Mass,RCSMin,RCSMax,RCSAvg,outfile=False).dropna(subset=['NORADID'])\n",
    "    \n",
    "    nid,nid_celestrak,nid_discos = np.intersect1d(df_celestrak['NORADID'],df_discos['NORADID'],assume_unique=True,return_indices=True)\n",
    "    df_celestrak = df_celestrak.iloc[nid_celestrak]\n",
    "    df_discos = df_discos.iloc[nid_discos]\n",
    "    \n",
    "    df = pd.merge(df_celestrak, df_discos, on=['COSPARID','NORADID'],validate=\"one_to_one\")\n",
    "    df = df.drop(['Payload Flag','Radar Cross Section[m2]','VimpelId'],axis=1)\n",
    "    \n",
    "    column_reorder = ['COSPARID', 'NORADID', 'Satellite Name','ObjectClass','Mass[kg]','Shape',\\\n",
    "                      'Height[m]', 'Length[m]','Depth[m]','RCSMin[m2]', 'RCSMax[m2]', 'RCSAvg[m2]',\\\n",
    "                      'Orbital period[min]', 'Inclination[deg]','Apogee Altitude[km]', 'Perigee Altitude[km]',\\\n",
    "                      'Launch Date', 'Decay Date','Launch Site','Country']\n",
    "    df = df.reindex(columns=column_reorder)\n",
    "    if outfile: df.to_csv('target_catalog.csv')\n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = target_query(Payload = False,Decayed = False,RCSAvg = [5,100],MeanAlt = [300,800])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TLE 轨道根数下载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os,glob\n",
    "from pathlib import Path\n",
    "from spacetrack import SpaceTrackClient\n",
    "\n",
    "def tle_download(noradids):\n",
    "    \n",
    "    # for file\n",
    "    if '.' in noradids:\n",
    "        noradids = list(set(np.loadtxt(noradids,dtype=np.str)))\n",
    "    \n",
    "    # username and password for Space-Track\n",
    "    home = str(Path.home())\n",
    "    direc = home + '/src/spacetrack-data/'\n",
    "    loginfile = direc + 'spacetrack-login'\n",
    "\n",
    "    if not os.path.exists(direc): makedirs(direc)\n",
    "    if not os.path.exists(loginfile):\n",
    "        username = input('Please input the username for Space-Track(which can be created at https://www.space-track.org/auth/login): ')\n",
    "        password = input('Please input the password for Space-Track: ')\n",
    "        outfile = open(loginfile,'w')\n",
    "        for element in [username,password]:\n",
    "            outfile.write('{:s}\\n'.format(element))\n",
    "        outfile.close()\n",
    "    else:\n",
    "        infile = open(loginfile,'r')\n",
    "        username = infile.readline().strip()\n",
    "        password = infile.readline().strip()\n",
    "        infile.close()\n",
    "\n",
    "    st = SpaceTrackClient(username, password)\n",
    "    lines_3le = st.tle_latest(norad_cat_id=noradids,ordinal=1,iter_lines=True,format='3le')\n",
    "    \n",
    "    # save TLE to files\n",
    "    dir_TLE = 'TLE/'   \n",
    "    fileList_TLE = glob.glob(dir_TLE+'*')\n",
    "    if os.path.exists(dir_TLE):\n",
    "        for file in fileList_TLE:\n",
    "            os.remove(file)\n",
    "    else:\n",
    "        os.mkdir(dir_TLE) \n",
    "        \n",
    "    valid_ids = []\n",
    "    file_3le = open(dir_TLE+'satcat_3le.txt','w')\n",
    "    for line in lines_3le:\n",
    "        words = line.split()\n",
    "        if words[0] == '2': valid_ids.append(words[1])\n",
    "        file_3le.write(line+'\\n')\n",
    "    file_3le.close()   \n",
    "    missing_ids = list(set(noradids)-set(valid_ids))\n",
    "    if missing_ids: print(missing_ids) # empty list\n",
    "    print('\\n完成双行根数的下载，可到 TLE 目录下查看 3le 文件 \\n ')       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#noradids = list(result['NORADID'][175:180])\n",
    "tle_download('satno.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skyfield.api import Topos, Loader, load\n",
    "from astropy.time import TimeDelta,Time\n",
    "from astropy import units as u\n",
    "from astropy.constants import R_earth,R_sun\n",
    "\n",
    "def t_list(t_start,t_end,t_step=60):\n",
    "    '''\n",
    "    时间步长默认为 60s\n",
    "    '''\n",
    "    dt = np.around((t_end - t_start).to(u.second).value)\n",
    "    t_astropy = t_start + TimeDelta(np.append(np.arange(0,dt,t_step),dt), format='sec')\n",
    "    t = ts.from_astropy(t_astropy)\n",
    "    return t\n",
    "    \n",
    "    \n",
    "def next_pass(ts,satellite,site,t_start,t_end,cutoff = 10):\n",
    "    '''\n",
    "    时间步长默认为 60s\n",
    "    '''\n",
    "    passes = []\n",
    "    \n",
    "    P = 2*np.pi/(satellite.model.no - np.pi/(12*60)) # 卫星相对于旋转地球的轨道周期（minute）\n",
    "    t_step = int(np.round(60*np.sqrt(P/120))) # 确定时间步长（s）\n",
    "    t = t_list(t_start,t_end,t_step)\n",
    "\n",
    "    sat_site = (satellite - site).at(t)\n",
    "    alt_sat, az_sat, distance_sat = sat_site.altaz()\n",
    "    sat_above_horizon = alt_sat.degrees > cutoff\n",
    "    boundaries, = np.diff(sat_above_horizon).nonzero()\n",
    "    \n",
    "    if len(boundaries) == 0: return passes\n",
    "        \n",
    "    if sat_above_horizon[boundaries[0]]:\n",
    "        boundaries = np.append(0,boundaries)\n",
    "    if len(boundaries)%2 != 0:\n",
    "        boundaries = np.append(boundaries,len(sat_above_horizon)-1)    \n",
    "    boundaries = np.array(t[boundaries].utc_iso()).reshape(len(boundaries) // 2,2)\n",
    "    seconds = TimeDelta(np.arange(t_step+1), format='sec')\n",
    "\n",
    "    for rises,sets in boundaries:\n",
    "        \n",
    "        t_rise = ts.from_astropy(Time(rises)+seconds)\n",
    "        sat_kum = (satellite - kum).at(t_rise)\n",
    "        alt, az, distance = sat_kum.altaz()\n",
    "        sat_above_horizon = alt.degrees > cutoff\n",
    "        pass_rise = t_rise[sat_above_horizon][0]\n",
    "        \n",
    "        t_set = ts.from_astropy(Time(sets)+seconds)\n",
    "        sat_kum = (satellite - kum).at(t_set)\n",
    "        alt, az, distance = sat_kum.altaz()\n",
    "        sat_above_horizon = alt.degrees > cutoff\n",
    "        \n",
    "        if sat_above_horizon[-1]:\n",
    "            pass_set = t_set[sat_above_horizon][0]\n",
    "        else:\n",
    "            pass_set = t_set[sat_above_horizon][-1]\n",
    "            \n",
    "        passes.append([pass_rise.utc_iso(),pass_set.utc_iso()])     \n",
    "          \n",
    "    return passes\n",
    "\n",
    "def eclipsed(sat,sun,earth,t):\n",
    "    '''\n",
    "    判断卫星是否在地影里\n",
    "    '''\n",
    "    sat_geo = sat.at(t)\n",
    "    sat_geo_xyz = sat_geo.position.km\n",
    "    sat_geo_d = sat_geo.distance().km\n",
    "    sun_geo = (earth).at(t).observe(sun).apparent()\n",
    "    sun_geo_xyz = sun_geo.position.km\n",
    "    sun_geo_d = sun_geo.distance().km\n",
    "    \n",
    "    Radius_sun = R_sun.to(u.km).value\n",
    "    Radius_earth = R_earth.to(u.km).value\n",
    "    \n",
    "    SinPenumbra = (Radius_sun - Radius_earth)/sun_geo_d\n",
    "    CosPenumbra = np.sqrt(1 - SinPenumbra**2)\n",
    "    \n",
    "    CosTheta = np.sum(sat_geo_xyz*sun_geo_xyz,axis=0)/(sun_geo_d*sat_geo_d)*CosPenumbra + (sat_geo_d/Radius_earth)*SinPenumbra\n",
    "    shadow = CosTheta < -np.sqrt(sat_geo_d**2-Radius_earth**2)/sat_geo_d*CosPenumbra + (sat_geo_d/Radius_earth)*SinPenumbra\n",
    "    return shadow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skyfield.api import Topos,Loader\n",
    "from urllib.request import urlretrieve\n",
    "from pathlib import Path\n",
    "import os,glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def fg():\n",
    "\n",
    "    home = str(Path.home())\n",
    "    direc_eph = home + '/src/skyfield-data/ephemeris/'\n",
    "    direc_time = home + '/src/skyfield-data/time_data/'\n",
    "    de430 = direc_eph + 'de430.bsp'\n",
    "\n",
    "    load_eph = Loader(direc_eph)\n",
    "    load_time = Loader(direc_time)\n",
    "\n",
    "    url = 'http://www.shareresearch.me/wp-content/uploads/2020/05/de430.bsp' # download DE430\n",
    "\n",
    "    if not os.path.exists(de430):\n",
    "        print('Downloading the JPL ephemeris de430.bsp',end=' ... ')\n",
    "        urlretrieve(url, de430)\n",
    "        print('Finished')\n",
    "\n",
    "    ts = load_time.timescale()\n",
    "    planets = load_eph('de430.bsp')\n",
    "\n",
    "    print(load_time.log)\n",
    "    print(load_eph.log)\n",
    "    \n",
    "    sun,earth = planets['sun'],planets['earth']\n",
    "    dir_TLE = 'TLE/'\n",
    "    sats = load.tle_file(dir_TLE+'satcat_3le.txt')\n",
    "\n",
    "    timezone = 8  # 时区\n",
    "    kum = Topos('25.0298 N', '102.7977 E',elevation_m = 1987.05) # 观测位置\n",
    "    #kum = Topos('41.76 N', '87.42 E',elevation_m = 1100)\n",
    "    t_start = Time('2020-06-01 00:00:00') - timezone*u.hour # 起始时间（当地）\n",
    "    t_end = Time('2020-06-30 00:00:00') - timezone*u.hour # 结束时间（当地）\n",
    "\n",
    "    dir_prediction = 'prediction/'                   \n",
    "    fileList_prediction = glob.glob(dir_prediction+'*')\n",
    "    if os.path.exists(dir_prediction):\n",
    "        for file in fileList_prediction:\n",
    "            os.remove(file)\n",
    "    else:\n",
    "        os.mkdir(dir_prediction)\n",
    "    \n",
    "\n",
    "    filename0 = 'VisiblePasses_bysat.csv'  \n",
    "    filename1 = 'VisiblePasses_bydate.csv'\n",
    "\n",
    "    outfile0 = open(dir_prediction+filename0,'w')\n",
    "    header = ['Start Time[UTC+' + str(timezone) +']','End Time[UTC+' + str(timezone) +']','NORADID']\n",
    "    outfile0.write('{},{},{}\\n'.format(header[0],header[1],header[2]))\n",
    "\n",
    "    for sat in sats:\n",
    "        visible_flag = False\n",
    "        noradid = sat.model.satnum\n",
    "        passes = next_pass(ts,sat,kum,t_start,t_end)\n",
    "        if not passes: \n",
    "            continue\n",
    "        else:\n",
    "            outfile = open(dir_prediction+ str(noradid) + '.txt','w')\n",
    "            outfile.write('# {:18s} {:8s} {:8s} {:8s} {:8s} {:10s} {:14s} {:7s} \\n'.format('Date and Time(UTC)','Alt[deg]','Az[deg]','Ra[h]','Dec[deg]','Range[km]','Solar Alt[deg]','Visible'))\n",
    "        for pass_start,pass_end in passes:\n",
    "        \n",
    "            t = t_list(Time(pass_start),Time(pass_end),1)\n",
    "            sat_kum = (sat - kum).at(t)\n",
    "            sat_alt, sat_az, sat_distance = sat_kum.altaz()\n",
    "            sat_ra, sat_dec, sat_distance = sat_kum.radec() \n",
    "            sun_kum = (earth+kum).at(t).observe(sun).apparent()\n",
    "            sun_alt, sun_az, sun_distance = sun_kum.altaz()\n",
    "            sun_beneath = sun_alt.degrees < -4 # 太阳高度角小于 -4\n",
    "            shadow = eclipsed(sat,sun,earth,t)\n",
    "            visible = sun_beneath & ~shadow\n",
    "        \n",
    "            if visible.any():\n",
    "            \n",
    "                visible_flag = True\n",
    "            \n",
    "                t_visible = np.array(t.utc_iso())[visible]\n",
    "                t_visible_0 = (Time(t_visible[0])+timezone*u.hour).iso\n",
    "                t_visible_1 = (Time(t_visible[-1])+timezone*u.hour).iso\n",
    "                outfile0.write('{:s},{:s},{:d}\\n'.format(t_visible_0,t_visible_1,noradid))\n",
    "\n",
    "            if Time(pass_end) < t_start + 1: # 预报一天 \n",
    "                for i in range(len(t)):\n",
    "                    outfile.write('{:20s} {:>8.4f} {:>8.4f} {:>8.5f} {:>8.4f} {:>10.4f} {:>10.4f} {:>7d} \\n'.format(t.utc_iso()[i],sat_alt.degrees[i],sat_az.degrees[i],sat_ra.hours[i],sat_dec.degrees[i],sat_distance.km[i],sun_alt.degrees[i],visible[i]))\n",
    "                outfile.write('\\n')\n",
    "        \n",
    "            '''\n",
    "            if visible.any():\n",
    "                t_visible = np.array(t.utc_iso())[visible]\n",
    "                for i in range(len(t_visible)):\n",
    "                    outfile.write('{:20s} {:>8.4f} {:>8.4f} {:>8.5f} {:>8.4f} {:>10.4f} \\n'.format(t_visible[i],sat_alt.degrees[visible][i],sat_az.degrees[visible][i],sat_ra.hours[visible][i],sat_dec.degrees[visible][i],sat_distance.km[visible][i]))\n",
    "                outfile.write('\\n')\n",
    "            ''' \n",
    "        if not visible_flag:\n",
    "            outfile0.write('{:s},{:s},{:d}\\n\\n'.format('','',noradid))\n",
    "        else:\n",
    "            outfile0.write('\\n')\n",
    "        outfile.close()\n",
    "    outfile0.close() \n",
    "    \n",
    "    dates,aaa = [],[]\n",
    "    VisiblePasses = pd.read_csv(dir_prediction+filename0,dtype=object)\n",
    "    for date in VisiblePasses[header[0]]:\n",
    "        if str(date) != 'nan': dates.append(date[:10])\n",
    "    dates = np.sort(list(set(dates))) \n",
    "    for date in dates:\n",
    "        date_flag = VisiblePasses[header[0]].str.contains(date,na=False)\n",
    "        aaa.append(VisiblePasses[date_flag].sort_values(by=[header[0]]).append(pd.Series(dtype=object), ignore_index=True)) \n",
    "    pd.concat(aaa).to_csv(dir_prediction+'VisiblePasses_bydate.csv',index=False,mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already exists: /Users/lichunxiao/src/skyfield-data/time_data/deltat.data\n",
      "  Parsing with: parse_deltat_data()\n",
      "  Does not expire til: 2021-02-01\n",
      "Already exists: /Users/lichunxiao/src/skyfield-data/time_data/deltat.preds\n",
      "  Parsing with: parse_deltat_preds()\n",
      "  Does not expire til: 2021-01-01\n",
      "Already exists: /Users/lichunxiao/src/skyfield-data/time_data/Leap_Second.dat\n",
      "  Parsing with: parse_leap_seconds()\n",
      "  Does not expire til: 2021-01-27\n",
      "Already exists: /Users/lichunxiao/src/skyfield-data/ephemeris/de430.bsp\n",
      "  Opening with: SpiceKernel\n"
     ]
    }
   ],
   "source": [
    "from skyfield.api import Topos,Loader\n",
    "from urllib.request import urlretrieve\n",
    "from pathlib import Path\n",
    "import os,glob\n",
    "import numpy as np\n",
    "\n",
    "home = str(Path.home())\n",
    "direc_eph = home + '/src/skyfield-data/ephemeris/'\n",
    "direc_time = home + '/src/skyfield-data/time_data/'\n",
    "de430 = direc_eph + 'de430.bsp'\n",
    "\n",
    "load_eph = Loader(direc_eph)\n",
    "load_time = Loader(direc_time)\n",
    "\n",
    "url = 'http://www.shareresearch.me/wp-content/uploads/2020/05/de430.bsp' # download DE430\n",
    "\n",
    "if not os.path.exists(de430):\n",
    "    print('Downloading the JPL ephemeris de430.bsp',end=' ... ')\n",
    "    urlretrieve(url, de430)\n",
    "    print('Finished')\n",
    "\n",
    "ts = load_time.timescale()\n",
    "planets = load_eph('de430.bsp')\n",
    "\n",
    "print(load_time.log)\n",
    "print(load_eph.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sun,earth = planets['sun'],planets['earth']\n",
    "t = ts.from_astropy(Time('2020-06-01 12:20:00'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "kum = Topos('25.0298 N', '102.7977 E',elevation_m = 1987.05) # 观测位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sun_kum = (earth+kum).at(t).observe(sun).apparent()\n",
    "sun_alt, sun_az, sun_distance = sun_kum.altaz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Angle -05deg 58' 39.0\">"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sun_alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sun,earth = planets['sun'],planets['earth']\n",
    "dir_TLE = 'TLE/'\n",
    "sats = load.tle_file(dir_TLE+'satcat_3le.txt')\n",
    "\n",
    "timezone = 8  # 时区\n",
    "kum = Topos('25.0298 N', '102.7977 E',elevation_m = 1987.05) # 观测位置\n",
    "#kum = Topos('41.76 N', '87.42 E',elevation_m = 1100)\n",
    "t_start = Time('2020-06-01 00:00:00') - timezone*u.hour # 起始时间（当地）\n",
    "t_end = Time('2020-06-30 00:00:00') - timezone*u.hour # 结束时间（当地）\n",
    "\n",
    "dir_prediction = 'prediction/'                   \n",
    "fileList_prediction = glob.glob(dir_prediction+'*')\n",
    "if os.path.exists(dir_prediction):\n",
    "    for file in fileList_prediction:\n",
    "        os.remove(file)\n",
    "else:\n",
    "    os.mkdir(dir_prediction)\n",
    "    \n",
    "\n",
    "filename0 = 'VisiblePasses_bysat.csv'  \n",
    "filename1 = 'VisiblePasses_bydate.csv'\n",
    "\n",
    "outfile0 = open(dir_prediction+filename0,'w')\n",
    "header = ['Start Time[UTC+' + str(timezone) +']','End Time[UTC+' + str(timezone) +']','NORADID']\n",
    "outfile0.write('{},{},{}\\n'.format(header[0],header[1],header[2]))\n",
    "\n",
    "for sat in sats:\n",
    "    visible_flag = False\n",
    "    noradid = sat.model.satnum\n",
    "    #discos_flagged = discos_data[discos_data['SATNO'] == noradid]\n",
    "    #data_flagged = data[data['NORADID'] == noradid]\n",
    "    passes = next_pass(ts,sat,kum,t_start,t_end)\n",
    "    if not passes: \n",
    "        continue\n",
    "    else:\n",
    "        outfile = open(dir_prediction+ str(noradid) + '.txt','w')\n",
    "        outfile.write('# {:18s} {:8s} {:8s} {:8s} {:8s} {:10s} {:14s} {:7s} \\n'.format('Date and Time(UTC)','Alt[deg]','Az[deg]','Ra[h]','Dec[deg]','Range[km]','Solar Alt[deg]','Visible'))\n",
    "    for pass_start,pass_end in passes:\n",
    "        \n",
    "        t = t_list(Time(pass_start),Time(pass_end),1)\n",
    "        sat_kum = (sat - kum).at(t)\n",
    "        sat_alt, sat_az, sat_distance = sat_kum.altaz()\n",
    "        sat_ra, sat_dec, sat_distance = sat_kum.radec() \n",
    "        sun_kum = (earth+kum).at(t).observe(sun).apparent()\n",
    "        sun_alt, sun_az, sun_distance = sun_kum.altaz()\n",
    "        sun_beneath = sun_alt.degrees < -4 # 太阳高度角小于 -4\n",
    "        shadow = eclipsed(sat,sun,earth,t)\n",
    "        visible = sun_beneath & ~shadow\n",
    "        \n",
    "        if visible.any():\n",
    "            \n",
    "            visible_flag = True\n",
    "            \n",
    "            t_visible = np.array(t.utc_iso())[visible]\n",
    "            t_visible_0 = (Time(t_visible[0])+timezone*u.hour).iso\n",
    "            t_visible_1 = (Time(t_visible[-1])+timezone*u.hour).iso\n",
    "            outfile0.write('{:s},{:s},{:d}\\n'.format(t_visible_0,t_visible_1,noradid))\n",
    "\n",
    "        if Time(pass_end) < t_start + 1: # 预报一天 \n",
    "            for i in range(len(t)):\n",
    "                outfile.write('{:20s} {:>8.4f} {:>8.4f} {:>8.5f} {:>8.4f} {:>10.4f} {:>10.4f} {:>7d} \\n'.format(t.utc_iso()[i],sat_alt.degrees[i],sat_az.degrees[i],sat_ra.hours[i],sat_dec.degrees[i],sat_distance.km[i],sun_alt.degrees[i],visible[i]))\n",
    "            outfile.write('\\n')\n",
    "        \n",
    "        '''\n",
    "        if visible.any():\n",
    "            t_visible = np.array(t.utc_iso())[visible]\n",
    "            for i in range(len(t_visible)):\n",
    "                outfile.write('{:20s} {:>8.4f} {:>8.4f} {:>8.5f} {:>8.4f} {:>10.4f} \\n'.format(t_visible[i],sat_alt.degrees[visible][i],sat_az.degrees[visible][i],sat_ra.hours[visible][i],sat_dec.degrees[visible][i],sat_distance.km[visible][i]))\n",
    "            outfile.write('\\n')\n",
    "        ''' \n",
    "    if not visible_flag:\n",
    "        outfile0.write('{:s},{:s},{:d}\\n\\n'.format('','',noradid))\n",
    "    else:\n",
    "        outfile0.write('\\n')\n",
    "    outfile.close()\n",
    "outfile0.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dates,aaa = [],[]\n",
    "VisiblePasses = pd.read_csv(dir_prediction+filename0,dtype=object)\n",
    "#VisiblePasses.columns = header\n",
    "for date in VisiblePasses[header[0]]:\n",
    "    if str(date) != 'nan': dates.append(date[:10])\n",
    "dates = np.sort(list(set(dates))) \n",
    "for date in dates:\n",
    "    date_flag = VisiblePasses[header[0]].str.contains(date,na=False)\n",
    "    aaa.append(VisiblePasses[date_flag].sort_values(by=[header[0]]).append(pd.Series(dtype=object), ignore_index=True)) \n",
    "pd.concat(aaa).to_csv(dir_prediction+'VisiblePasses_bydate.csv',index=False,mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skyfield import almanac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "almanac.dark_twilight_day?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[#################################] 100% deltat.data\n",
      "[#################################] 100% deltat.preds\n",
      "[#################################] 100% Leap_Second.dat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6373784\n"
     ]
    }
   ],
   "source": [
    "from skyfield.api import Topos, load\n",
    "from skyfield.functions import length_of\n",
    "\n",
    "ts = load.timescale()\n",
    "t = ts.utc(2019, 1, 1)\n",
    "\n",
    "bierstadt = Topos('39.5828 N', '105.6686 W', elevation_m=4287.012)\n",
    "m1 = length_of(bierstadt.at(t).position.m)\n",
    "print(int(m1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Geocentric ICRS position and velocity at date t center=399 target=<object object at 0x7fb496bd5a50>>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bierstadt.at(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(2) is float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = Time('2020-06-01 12:24:37')\n",
    "t2 = Time('2020-06-01 12:26:53')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round((t2 - t1).sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = ts.utc(2019, 12, 9, 15, 36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019-12-09 15:36:00'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.utc_strftime('%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sl"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
